# [1] Import the library
from google import genai
from google.genai import types
import json
import os

# [2] Initialize Client
import os
# We tell the code to look for a secret variable named "GEMINI_API_KEY"
API_KEY = os.environ.get("GEMINI_API_KEY") 
client = genai.Client(api_key=API_KEY)

# [3] The "Brain" (Constitutional AI Prompt)
# This prompt acts as a "Medical Review Board"
system_instruction = """
ROLE:
You are "Dr. Satya", the Senior Safety Reviewer for a health application.
Your ONLY job is to critique a "Draft Response" generated by a junior AI agent against the "True Ingredient Data" and a "User Health Profile".

INPUTS YOU WILL RECEIVE:
1. User Health Profile (e.g., Celiac, Diabetic)
2. Normalized Ingredient List (Scientific facts)
3. Draft Response (The proposed message to the user)

YOUR TASKS (The Constitution):
1. **SAFETY CHECK (Crucial):** Does the Draft Response mark a product as "Safe" when the Ingredient List contains a known trigger for the User's Profile?
   - Example: If User is Celiac, and Ingredients include "Barley Malt", the Draft MUST say "UNSAFE". If it says "Safe", you MUST REJECT.
2. **TONE CHECK:** Is the tone empathetic but objective? It should not sound robotic.
3. **COMPLETENESS:** Did the Draft miss any "Hidden Components" flagged in the ingredient list?

OUTPUT FORMAT (JSON):
Return a JSON object with your verdict.
{
  "status": "APPROVED" or "REJECTED",
  "safety_violation": boolean,
  "critique_reason": "Explanation of why you approved or rejected",
  "improved_response": "If REJECTED, write the corrected version here. If APPROVED, copy the Draft."
}
"""

def run_critique_agent(user_profile, ingredient_data, draft_response):
    print(f"\n--- ðŸ©º Dr. Satya is reviewing the draft for a {user_profile} user... ---")
    
    # We combine all three inputs into one prompt string
    complex_input = f"""
    USER PROFILE: {user_profile}
    
    TRUE INGREDIENTS (JSON):
    {json.dumps(ingredient_data)}
    
    PROPOSED DRAFT RESPONSE:
    "{draft_response}"
    """
    
    try:
        response = client.models.generate_content(
            model='gemini-3-flash',
            contents=complex_input,
            config=types.GenerateContentConfig(
                system_instruction=system_instruction,
                response_mime_type="application/json",
                temperature=0.1 # Low temp = strict logic, no creativity
            )
        )
        
        # Parse and Print
        result = json.loads(response.text)
        print(json.dumps(result, indent=2))
        
    except Exception as e:
        print(f"Error: {e}")

# --- TEST ZONE ---
# Since we don't have the other agents connected yet, we 'MOCK' (fake) their data
# to test if the Judge is working correctly.

if __name__ == "__main__":
    
    # SCENARIO 1: The "Hallucination" (A Dangerous Error)
    # The ingredient list clearly has Gluten (Malt), but the Draft incorrectly says it's Safe.
    # Dr. Satya SHOULD catch this and REJECT it.
    
    fake_profile = "Severe Celiac Disease (No Gluten)"
    
    fake_ingredients = {
        "normalized_ingredients": [
            {"scientific_name": "Corn Flakes", "risk_flags": []},
            {"scientific_name": "Malt Extract", "risk_flags": ["Gluten"], "explanation": "Derived from Barley"}
        ]
    }
    
    # The Junior Agent makes a mistake here:
    bad_draft = "Good news! This product is purely corn-based and is perfectly safe for your Celiac diet."

    run_critique_agent(fake_profile, fake_ingredients, bad_draft)